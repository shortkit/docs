---
title: "Data export"
description: "Export raw event data for custom analysis and data warehousing."
keywords: ["export", "data", "analytics", "API"]
---

The Export API allows you to export raw event data for custom analysis, data warehousing, and compliance requirements. Exports are asynchronous -- you create an export job, then download the result when it is ready.

## Endpoints

| Method | Endpoint | Auth | Description |
|--------|----------|------|-------------|
| `POST` | `/v1/analytics/export` | Secret key | Create an export job |
| `GET` | `/v1/analytics/export/{jobId}` | Secret key | Get export job status |
| `GET` | `/v1/analytics/exports` | Secret key | List export jobs |
| `DELETE` | `/v1/analytics/export/{jobId}` | Secret key | Cancel an export job |

## Create export

Request an export of raw event data.

```bash
POST /v1/analytics/export
```

### Request body

<ParamField body="startDate" type="string" required>
  Start date (ISO 8601: `YYYY-MM-DD`).
</ParamField>

<ParamField body="endDate" type="string" required>
  End date. Maximum 30 days from start.
</ParamField>

<ParamField body="eventTypes" type="string[]">
  Filter to specific event types (e.g., `["impression", "playStart", "completion"]`). Defaults to all event types.
</ParamField>

<ParamField body="format" type="string" default="jsonl">
  Output format: `jsonl` (JSON Lines) or `csv`.
</ParamField>

<ParamField body="filters" type="object">
  Optional filters to narrow the export.
  <Expandable title="properties">
    <ParamField body="contentIds" type="string[]">
      Filter to specific content IDs.
    </ParamField>
    <ParamField body="userIds" type="string[]">
      Filter to specific user IDs.
    </ParamField>
  </Expandable>
</ParamField>

<ParamField body="compression" type="string" default="gzip">
  Compression: `none` or `gzip`.
</ParamField>

### Example request

```bash
curl -X POST https://api.shortkit.dev/v1/analytics/export \
  -H "Authorization: Bearer sk_live_your_secret_key" \
  -H "Content-Type: application/json" \
  -d '{
    "startDate": "2026-01-01",
    "endDate": "2026-01-31",
    "eventTypes": ["impression", "playStart", "completion", "swipe"],
    "format": "jsonl",
    "compression": "gzip"
  }'
```

### Response

```json
{
  "data": {
    "jobId": "exp_abc123",
    "status": "processing",
    "estimatedSize": "250MB",
    "estimatedRowCount": 1250000,
    "estimatedCompletion": "2026-02-05T12:30:00Z",
    "createdAt": "2026-02-05T12:00:00Z"
  },
  "meta": {
    "request_id": "req_xyz789"
  }
}
```

## Get export status

Check the progress of an export job.

```bash
GET /v1/analytics/export/{jobId}
```

<ParamField path="jobId" type="string" required>
  Export job ID.
</ParamField>

### Response (processing)

```json
{
  "data": {
    "jobId": "exp_abc123",
    "status": "processing",
    "progress": 45,
    "processedRows": 562500,
    "estimatedRowCount": 1250000
  }
}
```

### Response (complete)

```json
{
  "data": {
    "jobId": "exp_abc123",
    "status": "complete",
    "downloadUrl": "https://exports.shortkit.dev/exp_abc123/data.jsonl.gz",
    "expiresAt": "2026-02-12T12:00:00Z",
    "fileSize": "245MB",
    "rowCount": 1250000,
    "completedAt": "2026-02-05T12:25:00Z"
  }
}
```

### Export statuses

| Status | Description |
|--------|-------------|
| `queued` | Job is queued for processing |
| `processing` | Export in progress |
| `complete` | Ready for download |
| `failed` | Export failed |
| `expired` | Download link has expired |

## List exports

List all export jobs for your organization.

```bash
GET /v1/analytics/exports
```

<ParamField query="limit" type="integer" default={20}>
  Items per page.
</ParamField>

<ParamField query="status" type="string">
  Filter by status.
</ParamField>

### Example request

```bash
curl "https://api.shortkit.dev/v1/analytics/exports?limit=10" \
  -H "Authorization: Bearer sk_live_your_secret_key"
```

### Response

```json
{
  "data": [
    {
      "jobId": "exp_abc123",
      "status": "complete",
      "dateRange": {
        "start": "2026-01-01",
        "end": "2026-01-31"
      },
      "format": "jsonl",
      "fileSize": "245MB",
      "createdAt": "2026-02-05T12:00:00Z",
      "completedAt": "2026-02-05T12:25:00Z"
    }
  ],
  "meta": {
    "total": 25,
    "request_id": "req_list456"
  }
}
```

## Cancel export

Cancel a pending or processing export job.

```bash
DELETE /v1/analytics/export/{jobId}
```

```bash
curl -X DELETE https://api.shortkit.dev/v1/analytics/export/exp_abc123 \
  -H "Authorization: Bearer sk_live_your_secret_key"
```

```json
{
  "data": {
    "jobId": "exp_abc123",
    "status": "cancelled"
  }
}
```

## Export formats

### JSON Lines (recommended)

One JSON object per line. Each line is a complete event record:

```jsonl
{"type":"impression","contentId":"sk_content_abc123","userId":"user_456","sessionId":"sess_xyz","timestamp":"2026-01-15T10:30:00Z","data":{"position":0,"entryPoint":"feed"}}
{"type":"playStart","contentId":"sk_content_abc123","userId":"user_456","sessionId":"sess_xyz","timestamp":"2026-01-15T10:30:01Z","data":{"startupTimeMs":245,"initialRendition":"720p"}}
{"type":"completion","contentId":"sk_content_abc123","userId":"user_456","sessionId":"sess_xyz","timestamp":"2026-01-15T10:30:34Z","data":{"watchTime":32.5,"looped":false}}
```

JSONL is recommended because event-specific `data` fields vary by type and are naturally represented as nested JSON.

### CSV

Tabular format with flattened fields:

```csv
type,contentId,userId,sessionId,timestamp,data.position,data.entryPoint,data.startupTimeMs,data.initialRendition,data.watchTime,data.looped
impression,sk_content_abc123,user_456,sess_xyz,2026-01-15T10:30:00Z,0,feed,,,,
playStart,sk_content_abc123,user_456,sess_xyz,2026-01-15T10:30:01Z,,,245,720p,,
completion,sk_content_abc123,user_456,sess_xyz,2026-01-15T10:30:34Z,,,,,32.5,false
```

## Processing large exports

For large exports, use a streaming parser to avoid loading the entire file into memory:

```javascript
const readline = require('readline');
const zlib = require('zlib');
const https = require('https');

https.get(downloadUrl, (response) => {
  const gunzip = zlib.createGunzip();
  const rl = readline.createInterface({
    input: response.pipe(gunzip)
  });

  rl.on('line', (line) => {
    const event = JSON.parse(line);
    processEvent(event);
  });
});
```

## BigQuery integration

Load JSONL exports directly into BigQuery for advanced analysis:

```bash
bq load \
  --source_format=NEWLINE_DELIMITED_JSON \
  --autodetect \
  your_dataset.shortkit_events \
  gs://your-bucket/shortkit-export.jsonl.gz
```

Or use a scheduled query to import exports on a recurring basis. The JSONL format maps directly to BigQuery's nested/repeated field model.

## Rate limits

| Limit | Value |
|-------|-------|
| Concurrent exports | 3 |
| Export jobs per day | 20 |
| Max date range | 30 days |
| Download link validity | 7 days |

## Next steps

<Columns cols={2}>
  <Card title="Analytics API" icon="chart-bar" href="/api/analytics">
    Query aggregated metrics without exporting.
  </Card>
  <Card title="Events API" icon="bolt" href="/api/events">
    Event ingestion reference.
  </Card>
</Columns>
